Known Issues (ordered by importance)
------------------------------------

- speed of media import. This is one of our biggest concerns currently.
  With a big import script adding many entries for a single file, the
  speed becomes really slow! When using sqlite3 database engine our
  machines (which aren't that slow) have an average rate of 1 file
  added per second, which is not acceptable and far from possible
  optimum especially if you have big collections.
  The yet to be included in the next release mysql storage option gives
  a significant speedup, at least in comparison. It raises to about 5
  files per second.
  
  Thus, in the configuration with sqlite3 storage engine the bottleneck
  of the system is obviously the sqlite3 engine. But when using mysql - the 
  bottleneck appears to migrate to 
    - libmagic, responsible for figuring out the mimetypes for unknown file
      extensions, and 
    - libid3, currently the only component of the metadata detection engine.
    
  The libmagic issue may be solved by mapping all relevant file extensions
  to the mime types directly and disabling parsing of the rest of the files.
  (These mappings can be easily formulated through the config file)
  This should actually be the default behaviour and it does not limit the
  normal use of the server in any way.
  
  libid3 may not be disabled, or we'll have no metadata-based virtual
  items. Unfortunately libid3 leaves rather few space for optimizations.
  In any case, also when further metadata detection libraries will be included
  I assume metadata detection will stay the bottleneck. The rest of the system
  is just much faster.
  
  We are looking for ideas to speed up metadata parsing.
  One of them is to have a concurrent metadata detection engine.
  I hope parsing files in parallel would bring some speedup.
  Currently we are elaborating this approach, but this won't be a
  revolution, I'm not even sure if it will yield any speedup at all -
  metadata parsing has apparently much more to do with hard drive IO 
  activity then with computational activity. We all know, how slow
  it is having several programs wigh frequent hard drive access to 
  work in parallel.

  Before mysql support arrives or for those doomed to use sqlite3
  for whatever reason there is an IMHO acceptable workaround.
  The sqlite3 database file may be placed into a ramdisk, this
  brings _significant_ speedup.
  NOTE: In this case you should take care of having a harddisk copy
  of the database. Shareing a nice script for this purpose would be
  appreciated.
  

- When directories are added recursively all subdirectories traversed
  are always created in the PC Directory, regardless if any files from
  those directories are taken to the database. This produces A LOT of
  garbage in the PC Directory and must be fixed ASAP.

- Deleting an arbitrary item does not trigger any consistency check.
  Virtual items do not relate to their referenced items. This must be
  changed. An item in a PC Directory would be the 'master copy'
  and once deleted all referring virtual items should be deleted as well.

- Make all metadata produced by javascript be stored in the database.
  Instead of iterating through all known metadata keys, should iterate
  through all meta properties of the object given to addCdsObject().
  (still don't know how to iterate over properties with spidermonkey)

- Session ID's do not timeout and/or are destroyed.

- opening web interface directly (not via bookmark file)
  with UI disabled will show a 404 error.
  A meaningfull error should be shown instead.

- XML parser is very limited. Does not even support comments :)
  Switching to expat would probably make sense. Correct XML parsing is 
  an essential capatility of a UPnP device.

  
Planned improvements / features (ordered by importance)
-------------------------------------------------------
- use the ref_id database field

- include mysql support (already working) into the main branch
  and write autoconf/automake stuff for conditional compilation of
  sqlite3 and/or mysql storage. (That's a challenge :)

- smarter configure script to optionally enable - disable features.
  Enable conditional compilation.
  
- refactor metadata_reader to have plugin architacture
- Flexible <res> tag handling, own field in the database
- url marshalling of <res> tags
- exiv2 thumbnail support
- readonly access to <res> metadata from
  javascript
- add auxilary metadata fields + readonly access from
  javascript


- introduce means to cascade scripts. Probably something like include()
  function or preprocessor directive.

- on the fly reloading of scripts and immediate automatic recreation
  of virtual structure. Should be simple - delete all virtual objects and
  pass every item inside the PC Directory to the script again. This will
  simplify development of JS scripts a lot.

- Virtual and corresponding items should share common metadata. Normally
  almost all metadata will be equal. Currently all data is copied for every
  created virtual item. Metadata handling functionality should be reviewed
  once more.

- Ability to explicitely define filesystem directories and files
  visible to the filesystem browser. Will be done using the
  include/exclude ruleset semantics similar to Jakarta Ant.
  
- Rewrite web presentation layer. Replace XML/XSL based presentation with
  plain HTML/CSS presentation. XML/XSL approach seemed to be attractive
  at the beginning, but as the server evolved it turned out to be
  cumbersome to work with and instead of simplifying development and
  providing better presentatin consistency did the opposite.
  An option is to do XSLT transformation server side, but this would
  increase system requirements to run the server and imply further
  dependencies on heavy libraries, which we would rather avoid.
  Another reason is browser compatibility.



